#!/usr/bin/env ruby

require 'open3'
require 'fileutils'
require 'etc'
require 'optparse'
require 'pty'
require 'digest/md5'
require 'socket'
require 'logger'
require 'set'
require 'securerandom'

def exec(cmd, opts: {}, debug: true)
  return Open3.capture3(opts, cmd).first unless debug

  LOGGER.info { cmd }
  LOGGER.debug { opts } unless opts.empty?

  stdout_str, stderr_str, status = Open3.capture3(opts, cmd)
  raise "#{cmd} failed" unless status.success?

  LOGGER.warn { stderr_str.strip } unless stderr_str.empty?
  LOGGER.debug { stdout_str.strip } unless stdout_str.empty?
  stdout_str
end

#    _
#   |_ |\ | \  /
#   |_ | \|  \/
#

# Cannot use refinement on `ENV`
#   as I don't know the `type` of ENV
# /!\ bad caching was changing the value of `mpi_env?, so no more caching
def env_fetch_first(*args, default: nil)
  ENV.values_at(*args).compact.first || default
end

#
#   \    / |_  o  _ |_  | o |_
#    \/\/  | | | (_ | | | | |_)
#
def ldconfig
  @ldconfig ||= begin
    ld_library_path = env_fetch_first('LD_LIBRARY_PATH', default: '').gsub(':', ' ')
    stdout_str = exec("ldconfig -vNX #{ld_library_path}",
                      opts: { 'PATH' => "#{env_fetch_first('PATH')}:/sbin" },
                      debug: false)
    stdout_str.split
  end
end

def whichlibs(pattern)
  ldconfig.reduce(['', []]) do |(header, path), l|
    # /opt/cray/libfabric/1.15.2.0/lib64:
    next [l.chop, path] if l.end_with?(':')

    # libfabric.so.1 -> libfabric.so.1.18.2
    lib = l.split(' -> ').first
    path << File.join(header, lib) if lib.match?(pattern)
    next [header, path]
  end.last
end

def whichlib64(pattern)
  # Use lazy to avoid `objdump` all the possible libs
  whichlibs(pattern).lazy.filter do |lib|
    stdout_str = exec("objdump -f #{lib}")
    # architecture: i386:x86-64, flags 0x00000150"
    stdout_str.match?(/architecture: \S+64/)
  end.first
end

#         _ ___    _
#   |\/| |_) |    |_ ._
#   |  | |  _|_   |_ | | \/
#
def in_mpi_env?
  !env_fetch_first('PALS_RANKID', 'PMI_RANK', 'OMPI_COMM_WORLD_RANK').nil?
end

# Multiple iprof may run in parallel (for example using ctest),
# so use a random hex by default
def mpi_job_id
  @mpi_job_id ||= env_fetch_first('PALS_APID', 'PMI_JOBID', 'OMPI_MCA_ess_base_jobid', default: SecureRandom.hex)
end

def mpi_rank_id
  env_fetch_first('PALS_RANKID', 'PMI_RANK', 'OMPI_COMM_WORLD_RANK', default: 0).to_i
end

def mpi_local_size
  env_fetch_first('PALS_LOCAL_SIZE', 'PMI_LOCAL_SIZE', 'OMPI_COMM_WORLD_LOCAL_SIZE', default: 1).to_i
end

def mpi_local_rank_id
  env_fetch_first('PALS_LOCAL_RANKID', 'PMI_LOCAL_RANK', 'OMPI_COMM_WORLD_LOCAL_RANK', default: 0).to_i
end

def mpi_local_master?
  mpi_local_rank_id == 0
end

def mpi_master?
  mpi_rank_id == 0
end

#    _
#   |_)  _. ._ ._ o  _  ._
#   |_) (_| |  |  | (/_ |
#
def count_file(folder)
  # \ls to avoid alias. Counter `.` and `..`, so remove them
  #  Will return -2 for a empty directory
  stdout_str = exec("\\ls -afq #{folder}", debug: false)
  stdout_str.lines.size - 2
end

FOLDER_JOBID = File.join('.thapi_lock', mpi_job_id)
# Put the user name, to avoid permission issue for people sharing nodes
SHARED_LOCAL_FILESYSTEM = File.join('/', 'dev', 'shm', Etc.getlogin, FOLDER_JOBID)
SHARED_GLOBAL_FILESYSTEM = File.join(env_fetch_first('HOME'), FOLDER_JOBID)

# Use a log distribution seem to be a good tradeoff
# between being nice to the FileSystem (not to many call)
# but not waiting to much
def busy_wait(&block)
  (2..).take_while { |i| block.call && sleep(Math.log(i)) }
end

# We know the local size, and the local id
#   Each process write a file, then we wait until all of them did it
#
# We cannot remove the local_path; this can lead to deadlock
#   One process finish and remove the file,
#   when another process is sleeping
# Hence, each local barrier should have a unique name
def local_barier(name)
  LOGGER.info { "Local_barier #{name}" }
  return unless in_mpi_env?

  folder = File.join(SHARED_LOCAL_FILESYSTEM, name)
  FileUtils.mkdir_p(File.join(folder, mpi_local_rank_id.to_s))
  busy_wait { count_file(folder) != mpi_local_size }
end

# We don't know the total number of ranks
#   -`PALS_NRANKS` look interesting but is not exported by default
#   - We may want to call `MPI_INIT()` our self, but that mean liking against MPI
#     making it a pain to install / configure THAPI
# We don't know either how many local masters we have
#   - MPI is not required to round-robin process between hosts
#   - We cannot use `PBS_NODEFILE`, as people can request N nodes, but launch <N process
#
# At the beginning of the script, each master will create a folder.
# Then, when hiting the barrier, each local master will remove his file
#  and wait until no more folders exist.
#
# This is racy! If one thread exit the barrier before any other enter it,
#    this thread will pass the barrier.
# We rely/We hope, that user will call an MPI_Barrier() && that we do enough work...
def init_global_barrier
  LOGGER.info { 'Init_global_barrier' }
  return unless in_mpi_env?

  f = File.join(SHARED_GLOBAL_FILESYSTEM, mpi_rank_id.to_s)
  FileUtils.mkdir_p(f)
  f
end

def global_barrier(f)
  LOGGER.info { 'Global_barrier' }
  return unless in_mpi_env?

  # Block until all the process have removed their sentinel,
  #    then master will clean the folder to be nice to the user
  #
  # Note that `mpi_master` can see the folder empty, and hence remove it
  #   at the same time as others threads sleep. They will wake up
  #   and see a deleted folder.
  # Fortunately `count_file` will return -2 for a non exciting folder
  #   hence we test for > 0 and not `!= 0`
  FileUtils.rm_rf(f)
  busy_wait { count_file(SHARED_GLOBAL_FILESYSTEM) > 0 }
  FileUtils.rm_rf(SHARED_GLOBAL_FILESYSTEM) if mpi_master?
end

#                        __
#   | _|_ _|_ ._   _    (_   _ _|_     ._
#   |_ |_  |_ | | (_|   __) (/_ |_ |_| |_)
#                  _|                  |

# We Cannot use "@ .. @" for libdir, bindir, and dataroodir
# as they will appear as bash "${exec_prefix}/lib"
# So for now we will rely on them having the default value,
#  (https://www.gnu.org/software/automake/manual/html_node/Standard-Directory-Variables.html)
# Will do some gsub + eval if required latter
EXEC_PREFIX = '@prefix@'
BINDIR = File.join(EXEC_PREFIX, 'bin')
LIBDIR = File.join(EXEC_PREFIX, 'lib')
PKGLIBDIR = File.join(LIBDIR, '@PACKAGE@')
PREFIX = '@prefix@'
DATAROOTDIR = File.join(PREFIX, 'share')
DATADIR = DATAROOTDIR

def env_tracers
  # Return the list of backends (used by local master to enable lttng events)
  # and the ENV used by any traced-ranks to preload THAPI tracers
  need_backend = mpi_local_master?
  need_env = Set[-1, mpi_rank_id].intersect?(OPTIONS[:'traced-ranks'])

  # Early exit to be nice with the FileSystem
  return [[], {}] unless need_backend || need_env

  h = Hash.new { |h, k| h[k] = [] }
  backends = []

  [%w[opencl cl libOpenCL libTracerOpenCL],
   %w[ze ze libze_loader libTracerZE],
   %w[cuda cuda libcuda libTracerCUDA],
   %w[hip hip libamdhip64 libTracerHIP]].each do |name, bt_name, lib, libtracer|
    # Backend requested, skip omp. It will be handled in a custom case bellow
    next unless OPTIONS[:'backend-name'].include?(bt_name)

    # Find and Save the original lib path
    libenv = "LTTNG_UST_#{name.upcase}_#{lib.upcase}"
    if (e = env_fetch_first(libenv))
      LOGGER.warn("#{libenv} was already set, will use this path #{e} for the #{name} loader")
      # TODO: Verify that this guy exist?
    elsif (libpath = whichlib64("#{lib}.so"))
      h[libenv] = libpath
    else
      LOGGER.warn("No #{lib}.so found in LD_LIBRARY_PATH")
      next
    end
    backends << bt_name
    # Add our "stud" library to the path
    h['LD_LIBRARY_PATH'] << File.join(PKGLIBDIR, name)
    # Preload our own lib
    h['LD_PRELOAD'] << File.join(LIBDIR, "#{libtracer}.so")
    h["LTTNG_UST_#{name.upcase}_PROFILE"] = 1 if OPTIONS[:profile]
    h["LTTNG_UST_#{name.upcase}_VERBOSE"] = 1 if LOGGER.level <= Logger::DEBUG
  end

  # Customization
  h['LTTNG_UST_ZE_PARANOID_DRIFT'] = 1 if OPTIONS[:'backend-name'].include?('ze') && OPTIONS[:profile]

  if OPTIONS[:'backend-name'].include?('omp')
    backends << 'omp'
    h['LTTNG_UST_OMP_INTEL'] = 1
    h['OMP_TOOL_LIBRARIES'] = File.join(PKGLIBDIR, 'libTracerOMPT.so')
  end

  backends = [] unless need_backend
  h = {} unless need_env
  LOGGER.info("Backends found: #{backends}")
  LOGGER.debug("User app env: #{h}")

  [backends, h.freeze]
end

def launch_usr_bin(env, cmd)
  LOGGER.info { "Launch_usr_bin #{cmd}" }
  # Transform list to bash env
  #   prepending to current env if already existing
  #   we don't modify `ENV` direclly to avoid by-construction any side-effect
  bash_env = env.map do |k, v|
    v.append(env_fetch_first(k)) if env_fetch_first(k)
    [k, [v].flatten.join(':')]
  end.to_h

  begin
    PTY.spawn(bash_env, *cmd) do |stdout, _stdin, _pid|
      stdout.each { |line| print line }
    rescue Errno::EIO
    end
  # Not sure how this exception can be triggered
  rescue PTY::ChildExited
    LOGGER.warn { 'Application Exited' }
  rescue Interrupt
    LOGGER.warn { 'Application Received Interrupt Signal' }
  end
end

def rename_root_to_human_readable_folder(lttng_output_root)
  # Multiple thapi can run concurrently.
  #   To avoid any race-conditions, we try to MKDIR until we succeed

  # This is solving a consensus for the name,
  # make it simpler and only allow "rank" per job to do it
  raise unless mpi_master?

  date = Time.now.strftime('%Y-%m-%d--%Hh%Mm%Ss')
  path = (0..).each do |i|
    prefix = i == 0 ? '' : "_#{i}"
    path = lttng_output_root.sub("--#{mpi_job_id}", "--#{date}#{prefix}")
    begin
      Dir.mkdir(path)
    rescue SystemCallError
      next
    else
      break path
    end
  end
  LOGGER.debug { "Rename #{lttng_output_root} -> #{path}" }
  File.rename(lttng_output_root, path)
  path
end

def enable_events_ze(lttng_session_uuid, channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  case tracing_mode
  when 'minimal'
    exec("#{lttng_enable} $(cat #{datadir}/babeltrace_zeprofiling_apis.txt)")
    exec("#{lttng_enable} lttng_ust_ze_properties:device_timer")
  when 'full'
    exec("#{lttng_enable} lttng_ust_ze_build:log*")
    exec("#{lttng_enable} lttng_ust_ze_profiling:*") if profiling
    exec("#{lttng_enable} lttng_ust_ze_properties:*")
    exec("#{lttng_enable} lttng_ust_ze:*")
  when 'default'
    exec("#{lttng_enable} lttng_ust_ze_build:log*")
    exec("#{lttng_enable} lttng_ust_ze_profiling:*") if profiling
    # Wildcard using the * character are supported at the end of tracepoint names.
    #   https://lttng.org/man/1/lttng-enable-event/v2.8/#doc-_understanding_event_rule_conditions
    # Disable-event doesn't have wildcards
    # So we enable and disable on the same line
    ze_properties_disable = ['lttng_ust_ze_properties:memory_info_properties',
                             'lttng_ust_ze_properties:memory_info_range']
    exec("#{lttng_enable} lttng_ust_ze_properties:* -x #{ze_properties_disable.join(',')}")

    ze_disable_events = ['lttng_ust_ze:zeKernelSetArgumentValue*', 'lttng_ust_ze:ze*Get*Properties*',
                         'lttng_ust_ze:zeKernelGetName']
    ze_disable_query = ['lttng_ust_ze:*QueryStatus', 'lttng_ust_ze:*ProcAddrTable*']
    ze_disable_loader = ['lttng_ust_ze:*Loader*']
    ze_disable = ze_disable_events + ze_disable_query + ze_disable_loader
    exec("#{lttng_enable} lttng_ust_ze:* -x #{ze_disable.join(',')}")
  else
    raise("Tracing mode #{tracing_mode} not supported")
  end
end

def enable_events_cl(lttng_session_uuid, channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  case tracing_mode
  when 'full'
    exec("#{lttng_enable} lttng_ust_opencl:*")
    exec("#{lttng_enable} lttng_ust_opencl_profiling:*") if profiling
    exec("#{lttng_enable} lttng_ust_opencl_devices:*")
    exec("#{lttng_enable} lttng_ust_opencl_arguments:*")
    exec("#{lttng_enable} lttng_ust_opencl_build:infos*")
  when 'default'
    exec("#{lttng_enable} lttng_ust_opencl_profiling:*") if profiling
    exec("#{lttng_enable} lttng_ust_opencl_devices:*")
    exec("#{lttng_enable} lttng_ust_opencl_arguments:*")
    exec("#{lttng_enable} lttng_ust_opencl_build:infos*")
    # Wildcard using the * character are supported at the end of tracepoint names.
    #   https://lttng.org/man/1/lttng-enable-event/v2.8/#doc-_understanding_event_rule_conditions
    # Disable-event doesn't have wildcards
    # So we enable and disable on the same line
    opencl_disable = ['lttng_ust_opencl:clSetKernelArg*', 'lttng_ust_opencl:clGetKernelArg*',
                      'lttng_ust_opencl:clSetKernelExecInfo*', 'lttng_ust_opencl:clGetKernelInfo*',
                      'lttng_ust_opencl:clGetMemAllocInfoINTEL*']

    exec("#{lttng_enable} lttng_ust_opencl:* -x #{opencl_disable.join(',')}")
  when 'minimal'
    LOGGER.debug("Tracing mode #{tracing_mode} not supported for OpenCL")
  else
    raise("Tracing mode #{tracing_mode} not supported")
  end
end

def enable_events_cuda(lttng_session_uuid, channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_cuda:*")
  exec("#{lttng_enable} lttng_ust_cuda_properties")
  exec("#{lttng_enable} lttng_ust_cuda_profiling:*") if profiling
end

def enable_events_hip(lttng_session_uuid, channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_hip:*")
end

def enable_events_omp(lttng_session_uuid, channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_ompt:*target*")
end

def enable_events_metadata(lttng_session_uuid, channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_thapi:*")
end

# TODO: Put in option
# Or env_fetch_first('HOME'),
THAPI_TMP_FOLDER_ROOT = '/tmp'

def get_lttng_paths
  #  We launch one daemon per Node
  #  Hence, the output needs to be prefixed by hostname
  #  so that each MPI local master can write to it
  lttng_output = File.join(THAPI_TMP_FOLDER_ROOT, 'lttng-traces', "thapi--#{mpi_job_id}", Socket.gethostname)

  # Each session will have an UUID.
  # This will be used to set LLTNG_HOME to a uuid for this run
  lttng_session_uuid = Digest::MD5.hexdigest(lttng_output)

  # Because $HOME is shared, the sessiond daemon will not be able to get a lock.
  #   `Error: Could not get lock file $USER/.lttng/lttng-sessiond.lck, another instance is running.`
  #   We will use the blanket solution of setting LLTNG_HOME waiting for the more granular solution
  lttng_home = File.join('/', 'tmp', lttng_session_uuid)

  [lttng_output, lttng_session_uuid, lttng_home]
end

def setup_lttng(lttng_output, lttng_session_uuid, lttng_home, backends)
  # Daemon will crash if LTTNG_HOME doesn't exist
  FileUtils.mkdir_p(lttng_home)

  # The daemon will be cleaned in the teardown
  exec('lttng-sessiond --daemonize')

  exec("lttng create #{lttng_session_uuid} -o #{lttng_output}")

  channel_name = 'blocking-channel'
  exec("lttng enable-channel --userspace --session=#{lttng_session_uuid} --blocking-timeout=inf #{channel_name}")
  exec("lttng add-context    --userspace --session=#{lttng_session_uuid} --channel=#{channel_name} -t vpid -t vtid")

  (backends + ['metadata']).each do |name|
    send("enable_events_#{name}", lttng_session_uuid, channel_name,
         tracing_mode: OPTIONS[:tracing_mode],
         profiling: OPTIONS[:profile])
  end
  exec("lttng start #{lttng_session_uuid}")
end

def teardown_lttng(lttng_session_uuid, lttng_home)
  exec("lttng destroy #{lttng_session_uuid}")
  # Need to kill the sessiond. It's safe because each job has their own
  #   In theory, opening this file is racy.
  #   It's possible that the sessiond spawned before writing in the file
  # In practice, there is so much work between the two. Should be ok
  pid = File.read(File.join(lttng_home, '.lttng', 'lttng-sessiond.pid')).to_i
  LOGGER.info('Killing sessiond')
  Process.kill('SIGKILL', pid)
end

# Start and Stop lttng
def trace(usr_argv)
  # All masters setup a future global barrier
  global_barrier_h = init_global_barrier if mpi_local_master?

  # Load Tracers and APILoaders Lib
  backends, h = env_tracers

  # All Need to set the LLTTNG_HOME
  # so they can have access to the daemon
  lttng_output, lttng_session_uuid, lttng_home = get_lttng_paths
  ENV['LTTNG_HOME'] = lttng_home
  # Only local master spawn LTTNG daemon and start session
  setup_lttng(lttng_output, lttng_session_uuid, lttng_home, backends) if mpi_local_master?
  local_barier('waiting_for_lttng_setup')
  # Launch User Command
  launch_usr_bin(h, usr_argv)

  # We need to be sure that all the local ranks finished
  # before local master stops the lttng session
  local_barier('waiting_for_application_ending')
  return unless mpi_local_master?

  teardown_lttng(lttng_session_uuid, lttng_home)
  # Preprocess trace
  preprocess_trace(lttng_output, backends, global_barrier_h)
end

#    _                                   _
#   |_)  _. |_   _  | _|_ ._ _.  _  _     )
#   |_) (_| |_) (/_ |  |_ | (_| (_ (/_   /_
#

def last_trace_saved
  Dir[File.join(env_fetch_first('HOME'), 'lttng-traces', 'thapi*')].max_by { |f| File.mtime(f) }
end

# TODO: Use babeltrace_thapi as a LIB not a binary

# The postprocess will as much as "per-node" as possible
# TODO: In the case of replay we need to print to some error if the saved-trace is not valid
# For now we will rely and the folder-name.
# This is not robust, we should rely on some `metadata` sometime

# postprocess_ctf_transformation
# Handle any processing need to be done after lttng-trace where generated

def preprocess_trace(lttng_output, backends, global_barrier_h)
  raise unless mpi_local_master?

  if OPTIONS.include?(:trace)
    # Do move to $home
    opts = nil
    ctf_output = File.join(env_fetch_first('HOME'), 'lttng-traces', "thapi--#{mpi_job_id}", Socket.gethostname)
  elsif OPTIONS.include?(:timeline)
    # Write Interval
    opts = 'to_interval '
    opts << "--backend #{backends.join(',')} "
    ctf_output = File.join(env_fetch_first('HOME'), 'lttng-traces', "thapi_interval--#{mpi_job_id}", Socket.gethostname)
  else
    opts = 'to_aggreg '
    opts << "--backend #{backends.join(',')} "
    # Write Aggreg
    ctf_output = File.join(env_fetch_first('HOME'), 'lttng-traces', "thapi_aggreg--#{mpi_job_id}", Socket.gethostname)
  end

  if opts
    opts << "--output #{ctf_output}"
    exec("#{BINDIR}/babeltrace_thapi #{opts} -- #{lttng_output}")
  else
    FileUtils.mkdir_p(File.dirname(ctf_output))
    FileUtils.mv(lttng_output, ctf_output)
  end

  # Global Barrier
  global_barrier(global_barrier_h)

  # Replace mpi_job_id with a better name
  rename_root_to_human_readable_folder(File.dirname(ctf_output)) if mpi_master?
end

# Handle stuff who need to be done by the master rank
# postprocess_master

def postprocess(folder)
  raise unless mpi_master?

  LOGGER.info { "postprocess #{folder}" }
  puts("Trace Location #{folder}")
  backends = OPTIONS[:'backend-name'].join(',')
  backend_level = OPTIONS[:backend].filter { |nl| nl.include?(':') }.join(',')

  if OPTIONS.include?(:trace)
    opts = 'trace '
    opts << '--restrict '
    opts << '--context '
    opts << "--backend #{backends} "
  elsif OPTIONS.include?(:timeline)
    opts = 'timeline '
    opts << "--backend #{backends} "
  else
    opts = 'tally '
    opts << '--display_kernel_verbose true ' if OPTIONS.include?(:'kernel-verbose')
    opts << '--display_metadata true ' if OPTIONS.include?(:metadata)
    opts << "--display_name_max_size #{OPTIONS[:'max-name-size']} "
    opts << '--display_mode json ' if OPTIONS.include?(:json)
    opts << "--backend #{backends} "
    opts << "--backend_level #{backend_level} " unless backend_level.empty?
    opts << '--display extended ' if OPTIONS.include?(:extended)
  end

  opts << '--no-muxer ' if folder.include?('thapi_interval') || folder.include?('thapi_aggreg')

  cmd = "#{BINDIR}/babeltrace_thapi #{opts} -- #{folder}"
  LOGGER.debug(cmd)
  IO.popen(cmd) do |stdout, _stdin, _pid|
    stdout.each { |line| print line }
  end
end

#
#    _                       _    ___
#   |_) _. ._ _ o ._   _    /  |   |
#   |  (_| | _> | | | (_|   \_ |_ _|_
#                      _|
parser = OptionParser.new

options = { tracing_mode: 'default', profile: true, backend: ['omp:2', 'cl:1', 'ze:1', 'cuda:1', 'hip:1'],
            'traced-ranks': Set[-1],
            'max-name-size': 80,
            debug: Logger::FATAL }

# Tracing
parser.on('-m', '--tracing-mode=MODE', %w[minimal default full], 'Define the category of events traced')
parser.on('--traced-ranks=RANK', Array, 'Select with MPI rank will be traced.',
          'Use -1 to mean all ranks.',
          "Default: #{options[:'traced-ranks'].join(',')}") do |ranks|
  ranks.map do |r|
    if r.match?(/^\d+$/)
      r.to_i
    else
      raise(OptionParser::ParseError,
            "Invalid value (#{r}). Only integer accepted")
    end
  end.to_set
end
parser.on('--[no-]profile', 'Device activities will not be profiled')

# General Options
parser.on('-b', '--backend BACKEND', Array, "Select which and how backends' need to handled.",
          'Format: backend_name[:backend_level],...',
          "Default: #{options[:backend].join(',')}")

# Analysis
parser.on('-r', '--replay [PATH]', 'Replay traces for post-mortem analysis')
parser.on('-t', '--trace', 'Pretty print the trace')
parser.on('-l', '--timeline', 'Dump a timeline of the trace.',
          "This will create a 'out.pftrace' file that can be opened in perfetto: https://ui.perfetto.dev/#!/viewer")
## Tally Specific Options
parser.on('-j', '--json', 'The tally will be dumped as json')
parser.on('-e', '--extended', 'The tally will be printed for each Hostname / Process / Thread / Device')
parser.on('-k', '--kernel-verbose',
          'The tally will report kernels execution time with SIMD width and global/local sizes')
parser.on('--max-name-size SIZE',
          OptionParser::DecimalInteger,
          'Maximum size allowed for kernels names.',
          'Use -1 to mean no limit.',
          "Default: #{options[:'max-name-size']}")

parser.on('--metadata', 'Display trace Metadata')
parser.on('-v', '--version', 'Display THAPI version')
parser.on('-h', '--help', 'Display this message')

parser.on('--debug [LEVEL]', OptionParser::DecimalInteger, 'Set the Level of debug',
          "By default the debug level is #{options[:debug]}.",
          "If LEVEL is omitted the debug level with be set to #{Logger::INFO}") { |d| d || Logger::INFO }

def print_help_and_exit(parser, exit_code: 1)
  puts(parser.help)
  puts(<<~EOF
                                                          __
    For complaints, praises, or bug reports please use: <(o )___
       https://github.com/argonne-lcf/THAPI              ( ._> /
       or send email to {apl,bvideau}@anl.gov             `---'
  EOF
      )
  exit(exit_code)
end

# Parsing ARGV
print_help_and_exit(parser) if ARGV.empty?

begin
  parser.parse!(into: options)
rescue StandardError => e
  puts("ERROR: #{e}")
  print_help_and_exit(parser)
end

options[:'backend-name'] = options[:backend].map { |name_level| name_level.split(':').first }
OPTIONS = options.freeze

# Setup Logger
LOGGER = Logger.new($stdout)
LOGGER.level = OPTIONS[:debug]

LOGGER.debug(OPTIONS)

# Action

# We don't rely on the Parser-OPT default help, as it doesn't print the footer
print_help_and_exit(parser, exit_code: 0) if OPTIONS.include?(:help)

if OPTIONS.include?(:version)
  puts(File.read(File.join(DATADIR, 'version')))
  exit(0)
end

# Right now, `replay` means no tracing.
# But we don't have a way of disabling post-processing
folder = OPTIONS.include?(:replay) ? OPTIONS[:replay] || last_trace_saved : trace(ARGV)
postprocess(folder) if mpi_master?
