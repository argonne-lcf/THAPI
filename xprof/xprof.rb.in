#!/usr/bin/env ruby

# We Cannot use "@ .. @" for libdir, bindir, and dataroodir
# as they will appear as bash "${exec_prefix}/lib"
# So for now we will rely on them having the default value,
#  (https://www.gnu.org/software/automake/manual/html_node/Standard-Directory-Variables.html)
# Will do some gsub + eval if required latter
EXEC_PREFIX = '@prefix@'
BINDIR = File.join(EXEC_PREFIX, 'bin')
LIBDIR = File.join(EXEC_PREFIX, 'lib')
PKGLIBDIR = File.join(LIBDIR, '@PACKAGE@')
PREFIX = '@prefix@'
DATAROOTDIR = File.join(PREFIX, 'share')
DATADIR = DATAROOTDIR

$LOAD_PATH.unshift(DATADIR) if File.directory?(DATADIR)
require 'open3'
require 'fileutils'
require 'etc'
require 'optparse_thapi'
require 'pty'
require 'digest/md5'
require 'socket'
require 'logger'
require 'set'
require 'securerandom'

def exec(cmd, opts: {}, debug: true)
  return Open3.capture3(opts, cmd).first unless debug

  LOGGER.info { cmd }
  LOGGER.debug { opts } unless opts.empty?

  stdout_str, stderr_str, status = Open3.capture3(opts, cmd)
  raise "#{cmd} failed" unless status.success?

  LOGGER.warn { stderr_str.strip } unless stderr_str.empty?
  LOGGER.debug { stdout_str.strip } unless stdout_str.empty?
  stdout_str
end

#    _
#   |_ |\ | \  /
#   |_ | \|  \/
#

# Cannot use refinement on `ENV`
#   as I don't know the `type` of ENV
# /!\ bad caching was changing the value of `mpi_env?, so no more caching
def env_fetch_first(*args, default: nil)
  ENV.values_at(*args).compact.first || default
end

#
#   \    / |_  o  _ |_  | o |_
#    \/\/  | | | (_ | | | | |_)
#
def ldconfig
  @ldconfig ||= begin
    ld_library_path = env_fetch_first('LD_LIBRARY_PATH', default: '').gsub(':', ' ')
    stdout_str = exec("ldconfig -vNX #{ld_library_path}",
                      opts: { 'PATH' => "#{env_fetch_first('PATH')}:/sbin" },
                      debug: false)
    stdout_str.split
  end
end

def whichlibs(pattern)
  ldconfig.reduce(['', []]) do |(header, path), l|
    # /opt/cray/libfabric/1.15.2.0/lib64:
    next [l.chop, path] if l.end_with?(':')

    # libfabric.so.1 -> libfabric.so.1.18.2
    lib = l.split(' -> ').first
    path << File.join(header, lib) if lib.match?(pattern)
    next [header, path]
  end.last
end

def whichlib64(pattern)
  # Use lazy to avoid `objdump` all the possible libs
  whichlibs(pattern).lazy.filter do |lib|
    stdout_str = exec("objdump -f #{lib}")
    # architecture: i386:x86-64, flags 0x00000150"
    stdout_str.match?(/architecture: \S+64/)
  end.first
end

#         _ ___    _
#   |\/| |_) |    |_ ._
#   |  | |  _|_   |_ | | \/
#
def in_mpi_env?
  !env_fetch_first('PALS_RANKID', 'PMI_RANK', 'OMPI_COMM_WORLD_RANK').nil?
end

# Multiple iprof may run in parallel (for example using ctest),
# so use a random hex by default
def mpi_job_id
  @mpi_job_id ||= env_fetch_first('PALS_APID', 'PMI_JOBID', 'OMPI_MCA_ess_base_jobid', default: SecureRandom.hex)
end

def mpi_rank_id
  env_fetch_first('PALS_RANKID', 'PMI_RANK', 'OMPI_COMM_WORLD_RANK', default: 0).to_i
end

def mpi_local_size
  env_fetch_first('PALS_LOCAL_SIZE', 'PMI_LOCAL_SIZE', 'OMPI_COMM_WORLD_LOCAL_SIZE', default: 1).to_i
end

def mpi_local_rank_id
  env_fetch_first('PALS_LOCAL_RANKID', 'PMI_LOCAL_RANK', 'OMPI_COMM_WORLD_LOCAL_RANK', default: 0).to_i
end

def mpi_local_master?
  mpi_local_rank_id == 0
end

def mpi_master?
  mpi_rank_id == 0
end

#    _                    _
#   |_ _  |  _|  _  ._   |_) _. _|_ |_
#   | (_) | (_| (/_ |    |  (_|  |_ | |
#

# Prefex of the thapi_trace_dir
def prefix_processed_trace
  if OPTIONS.include?(:trace) || !OPTIONS[:analysis]
    ''
  elsif OPTIONS.include?(:timeline)
    '_interval'
  else
    '_aggreg'
  end
end

# THAPI/xprof use multiple folder
# - lttng_trace_dir_tmp
#     where the 'raw' lttng trace is saved.
#     For performance we store in a `tmp` folder.
#     When "on the fly" analys will be possible, this should not potential OOM
# - thapi_trace_dir_tmp
#     Where the "pre-processed / analysed / condensed" trace a saved.
#     Each nodes need to aggree on a root folder to write into.
#  - thapi_trace_dir_root
#     Final directory exposed to the user. The `master rank`  rename the `thapi_trace_dir_tmp`
#     with a more "friendly" name.
#
#  - lttng_home_dir
#     Home of the lttng daemon

def lttng_trace_dir_tmp
  File.join('/', 'tmp', "thapi--#{mpi_job_id}", Socket.gethostname)
end

def thapi_trace_dir_tmp
  File.join(env_fetch_first('HOME'), 'thapi-traces', "thapi#{prefix_processed_trace}--#{mpi_job_id}",
            Socket.gethostname)
end

def lttng_home_dir
  File.join('/', 'tmp', "lttng_home--#{mpi_job_id}")
end

def thapi_trace_dir_root
  raise unless mpi_master?

  @thapi_trace_dir_root ||= begin
    # Multiple thapi can run concurrently.
    #   To avoid any race-conditions, we try to MKDIR until we succeed

    # This is solving a consensus for the name,
    # make it simpler and only allow "rank" per job to do it
    # Use ISO8601 extended format
    date = DateTime.now.iso8601
    (0..).each do |i|
      prefix = i == 0 ? '' : "_#{i}"
      thapi_uuid = date + prefix
      path = File.join(env_fetch_first('HOME'), 'thapi-traces', "thapi#{prefix_processed_trace}--#{thapi_uuid}")
      begin
        Dir.mkdir(path)
      rescue SystemCallError
        next
      else
        break path
      end
    end
  end
end

#    _
#   |_)  _. ._ ._ o  _  ._
#   |_) (_| |  |  | (/_ |
#
class Sync_daemon
  SIGRTMIN = 34
  RT_SIGNAL_READY = SIGRTMIN
  RT_SIGNAL_GLOBAL_BARRIER = SIGRTMIN + 1
  RT_SIGNAL_LOCAL_BARRIER = SIGRTMIN + 2
  RT_SIGNAL_FINISH = SIGRTMIN + 3

  def lazy_exec(&block)
    return unless in_mpi_env?

    Signal.trap(RT_SIGNAL_READY) do
      return
    end
    block.call
    sleep
  end

  def initialize
    LOGGER.info { 'Init Sync_daemon' }
    lazy_exec do
      daemon = if File.exist?("#{__dir__}/sync_daemon_mpi")
                 "#{__dir__}/sync_daemon_mpi"
               else
                 "#{__dir__}/sync_daemon_fs"
               end
      LOGGER.debug { "spawn(#{daemon} #{Process.pid})" }
      @pid = spawn("#{daemon} #{Process.pid}")
    end
  end

  def finalize
    lazy_exec do
      `kill -#{RT_SIGNAL_FINISH} #{@pid}`
    end
  end

  def local_barrier(name)
    LOGGER.info { "Local_barrier #{name}" }
    lazy_exec do
      `kill -#{RT_SIGNAL_LOCAL_BARRIER} #{@pid}`
    end
  end

  def global_barrier
    LOGGER.info { 'global_barrier' }
    lazy_exec do
      `kill -#{RT_SIGNAL_GLOBAL_BARRIER} #{@pid}`
    end
  end
end

#                        __
#   | _|_ _|_ ._   _    (_   _ _|_     ._
#   |_ |_  |_ | | (_|   __) (/_ |_ |_| |_)
#                  _|                  |
def lttng_session_uuid
  Digest::MD5.hexdigest(lttng_trace_dir_tmp)
end

def lttng_session_uuid
  Digest::MD5.hexdigest(lttng_trace_dir_tmp)
end

def env_tracers
  # Return the list of backends (used by local master to enable lttng events)
  # and the ENV used by any traced-ranks to preload THAPI tracers
  need_backend = mpi_local_master?
  need_env = Set[-1, mpi_rank_id].intersect?(OPTIONS[:'traced-ranks'])

  # Early exit to be nice with the FileSystem
  return [[], {}] unless need_backend || need_env

  h = Hash.new { |h, k| h[k] = [] }
  backends = []

  [%w[opencl cl libOpenCL libTracerOpenCL],
   %w[ze ze libze_loader libTracerZE],
   %w[cuda cuda libcuda libTracerCUDA],
   %w[hip hip libamdhip64 libTracerHIP]].each do |name, bt_name, lib, libtracer|
    # Backend requested, skip omp. It will be handled in a custom case bellow
    next unless OPTIONS[:'backend-names'].include?(bt_name)

    # Find and Save the original lib path
    libenv = "LTTNG_UST_#{name.upcase}_#{lib.upcase}"
    if (e = env_fetch_first(libenv))
      LOGGER.warn("#{libenv} was already set, will use this path #{e} for the #{name} loader")
      # TODO: Verify that this guy exist?
    elsif (libpath = whichlib64("#{lib}.so"))
      h[libenv] = libpath
    else
      LOGGER.warn("No #{lib}.so found in LD_LIBRARY_PATH")
      next
    end
    backends << bt_name
    # Add our "stud" library to the path
    h['LD_LIBRARY_PATH'] << File.join(PKGLIBDIR, name)
    # Preload our own lib
    h['LD_PRELOAD'] << File.join(LIBDIR, "#{libtracer}.so")
    h["LTTNG_UST_#{name.upcase}_PROFILE"] = 1 if OPTIONS[:profile]
    h["LTTNG_UST_#{name.upcase}_VERBOSE"] = 1 if LOGGER.level <= Logger::DEBUG
  end

  # Customization
  h['LTTNG_UST_ZE_PARANOID_DRIFT'] = 1 if OPTIONS[:'backend-names'].include?('ze') && OPTIONS[:profile]

  if OPTIONS[:'backend-names'].include?('omp')
    backends << 'omp'
    h['LTTNG_UST_OMP_INTEL'] = 1
    h['OMP_TOOL_LIBRARIES'] = File.join(PKGLIBDIR, 'libTracerOMPT.so')
  end

  backends = [] unless need_backend
  h = {} unless need_env
  LOGGER.info("Backends found: #{backends}")
  LOGGER.debug("User app env: #{h}")

  [backends, h.freeze]
end

def launch_usr_bin(env, cmd)
  LOGGER.info { "Launch_usr_bin #{cmd}" }
  # Transform list to bash env
  #   prepending to current env if already existing
  #   we don't modify `ENV` direclly to avoid by-construction any side-effect
  bash_env = env.map do |k, v|
    v.append(env_fetch_first(k)) if env_fetch_first(k)
    [k, [v].flatten.join(':')]
  end.to_h

  begin
    PTY.spawn(bash_env, *cmd) do |stdout, _stdin, _pid|
      stdout.each { |line| print line }
    rescue Errno::EIO
    end
  # Not sure how this exception can be triggered
  rescue PTY::ChildExited
    LOGGER.warn { 'Application Exited' }
  rescue Interrupt
    LOGGER.warn { 'Application Received Interrupt Signal' }
  end
end

def enable_events_ze(channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  case tracing_mode
  when 'minimal'
    exec("#{lttng_enable} $(cat #{datadir}/babeltrace_zeprofiling_apis.txt)")
    exec("#{lttng_enable} lttng_ust_ze_properties:device_timer")
  when 'full'
    exec("#{lttng_enable} lttng_ust_ze_build:log*")
    exec("#{lttng_enable} lttng_ust_ze_profiling:*") if profiling
    exec("#{lttng_enable} lttng_ust_ze_properties:*")
    exec("#{lttng_enable} lttng_ust_ze:*")
  when 'default'
    exec("#{lttng_enable} lttng_ust_ze_build:log*")
    exec("#{lttng_enable} lttng_ust_ze_profiling:*") if profiling
    # Wildcard using the * character are supported at the end of tracepoint names.
    #   https://lttng.org/man/1/lttng-enable-event/v2.8/#doc-_understanding_event_rule_conditions
    # Disable-event doesn't have wildcards
    # So we enable and disable on the same line
    ze_properties_disable = ['lttng_ust_ze_properties:memory_info_properties',
                             'lttng_ust_ze_properties:memory_info_range']
    exec("#{lttng_enable} lttng_ust_ze_properties:* -x #{ze_properties_disable.join(',')}")

    ze_disable_events = ['lttng_ust_ze:zeKernelSetArgumentValue*', 'lttng_ust_ze:ze*Get*Properties*',
                         'lttng_ust_ze:zeKernelGetName']
    ze_disable_query = ['lttng_ust_ze:*QueryStatus', 'lttng_ust_ze:*ProcAddrTable*']
    ze_disable_loader = ['lttng_ust_ze:*Loader*']
    ze_disable = ze_disable_events + ze_disable_query + ze_disable_loader
    exec("#{lttng_enable} lttng_ust_ze:* -x #{ze_disable.join(',')}")
  else
    raise("Tracing mode #{tracing_mode} not supported")
  end
end

def enable_events_cl(channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  case tracing_mode
  when 'full'
    exec("#{lttng_enable} lttng_ust_opencl:*")
    exec("#{lttng_enable} lttng_ust_opencl_profiling:*") if profiling
    exec("#{lttng_enable} lttng_ust_opencl_devices:*")
    exec("#{lttng_enable} lttng_ust_opencl_arguments:*")
    exec("#{lttng_enable} lttng_ust_opencl_build:infos*")
  when 'default'
    exec("#{lttng_enable} lttng_ust_opencl_profiling:*") if profiling
    exec("#{lttng_enable} lttng_ust_opencl_devices:*")
    exec("#{lttng_enable} lttng_ust_opencl_arguments:*")
    exec("#{lttng_enable} lttng_ust_opencl_build:infos*")
    # Wildcard using the * character are supported at the end of tracepoint names.
    #   https://lttng.org/man/1/lttng-enable-event/v2.8/#doc-_understanding_event_rule_conditions
    # Disable-event doesn't have wildcards
    # So we enable and disable on the same line
    opencl_disable = ['lttng_ust_opencl:clSetKernelArg*', 'lttng_ust_opencl:clGetKernelArg*',
                      'lttng_ust_opencl:clSetKernelExecInfo*', 'lttng_ust_opencl:clGetKernelInfo*',
                      'lttng_ust_opencl:clGetMemAllocInfoINTEL*']

    exec("#{lttng_enable} lttng_ust_opencl:* -x #{opencl_disable.join(',')}")
  when 'minimal'
    LOGGER.debug("Tracing mode #{tracing_mode} not supported for OpenCL")
  else
    raise("Tracing mode #{tracing_mode} not supported")
  end
end

def enable_events_cuda(channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_cuda:*")
  exec("#{lttng_enable} lttng_ust_cuda_properties")
  exec("#{lttng_enable} lttng_ust_cuda_profiling:*") if profiling
end

def enable_events_hip(channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_hip:*")
end

def enable_events_omp(channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_ompt:*target*")
end

def enable_events_metadata(channel_name, tracing_mode: 'default', profiling: true)
  lttng_enable = "lttng enable-event --userspace --session=#{lttng_session_uuid} --channel=#{channel_name}"
  exec("#{lttng_enable} lttng_ust_thapi:*")
end

def setup_lttng(backends)
  raise unless mpi_local_master?

  # Spawning the sessiond Daemon will crash
  #   if LTTNG_HOME doesn't exist
  FileUtils.mkdir_p(lttng_home_dir)
  exec('lttng-sessiond --daemonize')
  exec("lttng create #{lttng_session_uuid} -o #{lttng_trace_dir_tmp}")

  channel_name = 'blocking-channel'
  exec("lttng enable-channel --userspace --session=#{lttng_session_uuid} --blocking-timeout=inf #{channel_name}")
  exec("lttng add-context    --userspace --session=#{lttng_session_uuid} --channel=#{channel_name} -t vpid -t vtid")

  # Enable backend events
  (backends + ['metadata']).each do |name|
    send("enable_events_#{name}", channel_name,
         tracing_mode: OPTIONS[:'tracing-mode'],
         profiling: OPTIONS[:profile])
  end
  exec("lttng start #{lttng_session_uuid}")
end

def teardown_lttng
  exec("lttng destroy #{lttng_session_uuid}")
  # Need to kill the sessiond Daemon. It's safe because each job has their own
  #
  # In theory, opening the lttng-sessiond.pid file is racy.
  # It's possible that the sessiond spawned, and didn't yet wrote the file
  # In practice, there is lot of work between the spawn and the write, so should be ok
  pid = File.read(File.join(lttng_home_dir, '.lttng', 'lttng-sessiond.pid')).to_i
  LOGGER.info('Killing sessiond')
  Process.kill('SIGKILL', pid)
  FileUtils.rm_f(lttng_home_dir)
end

#    _                                   _
#   |_)  _. |_   _  | _|_ ._ _.  _  _     )
#   |_) (_| |_) (/_ |  |_ | (_| (_ (/_   /_
#

# TODO: Use babeltrace_thapi as a LIB not a binary

def on_node_processing(backends, syncd)
  raise unless mpi_local_master?

  opts = if OPTIONS.include?(:trace)
           # Do move to $home
           nil
         elsif OPTIONS.include?(:timeline)
           # Write Interval
           'to_interval '
         else
           'to_aggreg '
         end

  if opts && OPTIONS[:analysis]
    opts << "--output #{thapi_trace_dir_tmp} "
    opts << "--backends #{backends.join(',')} "
    exec("#{BINDIR}/babeltrace_thapi #{opts} -- #{lttng_trace_dir_tmp}")
    FileUtils.rm_f(lttng_trace_dir_tmp)
  else
    FileUtils.mkdir_p(File.dirname(thapi_trace_dir_tmp))
    FileUtils.mv(lttng_trace_dir_tmp, thapi_trace_dir_tmp)
  end

  # Global Barrier
  syncd.global_barrier

  # Replace mpi_job_id with a better name
  return unless mpi_master?

  thapi_trace_dir_tmp_root = File.dirname(thapi_trace_dir_tmp)
  FileUtils.mv(thapi_trace_dir_tmp_root, thapi_trace_dir_root)
  thapi_trace_dir_root
end

# Start, Stop lttng, amd do the on-node analsysis
def trace_and_on_node_processing(usr_argv)
  # All masters setup a future global barrier
  syncd = Sync_daemon.new

  # Load Tracers and APILoaders Lib
  backends, h = env_tracers

  # All ranks need to set the LLTTNG_HOME env
  # so they can have access to the daemon
  ENV['LTTNG_HOME'] = lttng_home_dir
  # Only local master spawn LTTNG daemon and start session
  setup_lttng(backends) if mpi_local_master?
  syncd.local_barrier('waiting_for_lttng_setup')
  # Launch User Command
  launch_usr_bin(h, usr_argv)

  # We need to be sure that all the local ranks finished
  # before local master stops the lttng session
  syncd.local_barrier('waiting_for_application_ending')
  return unless mpi_local_master?

  teardown_lttng
  # Preprocess trace
  on_node_processing(backends, syncd)
end

def global_processing(folder)
  raise unless mpi_master?

  LOGGER.info { "postprocess #{folder}" }

  backends = OPTIONS[:'backend-names'].join(',')
  backend_levels = OPTIONS[:backends].filter { |nl| nl.include?(':') }.join(',')

  cmdname = "#{BINDIR}/babeltrace_thapi"

  args = []

  if OPTIONS.include?(:trace)
    if folder.include?('_interval') || folder.include?('_aggreg')
      raise 'Cannot show the trace of an interval or aggregated trace'
    end

    args += ['trace', '--restrict', '--context', '--backends', backends]
  elsif OPTIONS.include?(:timeline)
    raise 'Cannot show the trace of an aggreg trace' if folder.include?('_aggreg')

    args += ['timeline', '--backends', backends]
  else
    args += ['tally']
    args << '--display_kernel_verbose' << 'true' if OPTIONS.include?(:'kernel-verbose')
    args << '--display_metadata' << 'true' if OPTIONS.include?(:metadata)
    args << '--display_name_max_size' << OPTIONS[:'max-name-size'].to_s
    args << '--display_mode' << 'json' if OPTIONS.include?(:json)
    args << '--backends' << backends
    args << '--backend_levels' << backend_levels unless backend_levels.empty?
    args << '--display' << 'extended' if OPTIONS.include?(:extended)
  end

  args << '--no-muxer' if folder.include?('thapi_interval') || folder.include?('thapi_aggreg')

  args += ['--', folder]

  LOGGER.debug(cmdname)
  LOGGER.debug(args)
  IO.popen([cmdname, *args]) do |stdout, _stdin, _pid|
    stdout.each { |line| print line }
  end
end

#
#    _                       _    ___
#   |_) _. ._ _ o ._   _    /  |   |
#   |  (_| | _> | | | (_|   \_ |_ _|_
#                      _|
def last_trace_saved
  Dir[File.join(env_fetch_first('HOME'), 'thapi-traces', 'thapi*')].max_by { |f| File.mtime(f) }
end

# Avoid load problem
if __FILE__ == $0
  parser = OptionParserWithDefaultAndValidation.new

  # Tracing
  parser.on('-m', '--tracing-mode MODE', 'Define the category of events traced', default: 'default',
                                                                                 allowed: %w[minimal default full])
  parser.on('--traced-ranks RANK', Array, 'Select with MPI rank will be traced.',
            'Use -1 to mean all ranks.',
            default: Set[-1]) do |ranks|
    ranks.map do |r|
      if r.match?(/^\d+$/)
        r.to_i
      else
        raise(OptionParser::ParseError,
              "Invalid value (#{r}). Only integer accepted")
      end
    end.to_set
  end
  parser.on('--[no-]profile', 'Trigger for device activities profiling', default: true)
  parser.on('--[no-]analysis', 'Trigger for analysis', default: true)

  # General Options
  parser.on('-b', '--backends BACKENDS', Array, "Select which and how backends' need to handled.",
            'Format: backend_name[:backend_level],...',
            default: ['omp:2', 'cl:1', 'ze:1', 'cuda:1', 'hip:1'])

  # Analysis
  parser.on('-r', '--replay [PATH]', 'Replay traces for post-mortem analysis')
  parser.on('-t', '--trace', 'Pretty print the trace')
  parser.on('-l', '--timeline', 'Dump a timeline of the trace.',
            "This will create a 'out.pftrace' file that can be opened in perfetto: https://ui.perfetto.dev/#!/viewer")
  ## Tally Specific Options
  parser.on('-j', '--json', 'The tally will be dumped as json')
  parser.on('-e', '--extended', 'The tally will be printed for each Hostname / Process / Thread / Device')
  parser.on('-k', '--kernel-verbose',
            'The tally will report kernels execution time with SIMD width and global/local sizes')
  parser.on('--max-name-size SIZE',
            OptionParser::DecimalInteger,
            'Maximum size allowed for kernels names.',
            'Use -1 to mean no limit.', default: 80)

  parser.on('--metadata', 'Display trace Metadata') do
    puts File.read(File.join(DATADIR, 'version'))
    exit
  end

  parser.on('-h', '--help', 'Display this message') { print_help_and_exit(parser, exit_code: 0) }

  parser.on('--debug [LEVEL]', OptionParser::DecimalInteger, 'Set the Level of debug',
            "If LEVEL is omitted the debug level with be set to #{Logger::INFO}", default: Logger::FATAL) { |d| d || Logger::INFO }

  def print_help_and_exit(parser, exit_code: 1)
    puts(parser.help)
    puts(<<~EOF
                                                            __
      For complaints, praises, or bug reports please use: <(o )___
         https://github.com/argonne-lcf/THAPI              ( ._> /
         or send email to {apl,bvideau}@anl.gov             `---'
    EOF
        )
    exit(exit_code)
  end

  # Parsing ARGV
  print_help_and_exit(parser) if ARGV.empty?

  options = {}
  begin
    parser.parse!(into: options)
  rescue StandardError => e
    puts("ERROR: #{e}")
    print_help_and_exit(parser)
  end

  options[:'backend-names'] = options[:backends].map { |name_level| name_level.split(':').first }
  OPTIONS = options.freeze

  # Setup Logger
  LOGGER = Logger.new($stdout)
  LOGGER.level = OPTIONS[:debug]
  LOGGER.debug(OPTIONS)

  # Right now, `replay` means no tracing.
  # But we don't have a way of disabling post-processing
  folder = OPTIONS.include?(:replay) ? OPTIONS[:replay] || last_trace_saved : trace_and_on_node_processing(ARGV)
  if mpi_master?
    puts("THAPI: Trace Location #{folder}")
    global_processing(folder) if OPTIONS[:analysis]
  end

end
